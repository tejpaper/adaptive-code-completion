@misc{lu2021,
  title         = {CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation},
  author        = {Shuai Lu and Daya Guo and Shuo Ren and Junjie Huang and Alexey Svyatkovskiy and Ambrosio Blanco and Colin Clement and Dawn Drain and Daxin Jiang and Duyu Tang and Ge Li and Lidong Zhou and Linjun Shou and Long Zhou and Michele Tufano and Ming Gong and Ming Zhou and Nan Duan and Neel Sundaresan and Shao Kun Deng and Shengyu Fu and Shujie Liu},
  year          = {2021},
  eprint        = {2102.04664},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2102.04664}
}

@article{ciniselli2021,
  title     = {An Empirical Study on the Usage of Transformer Models for Code Completion},
  issn      = {2326-3881},
  url       = {http://dx.doi.org/10.1109/TSE.2021.3128234},
  doi       = {10.1109/tse.2021.3128234},
  journal   = {IEEE Transactions on Software Engineering},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Ciniselli, Matteo and Cooper, Nathan and Pascarella, Luca and Mastropaolo, Antonio and Aghajani, Emad and Poshyvanyk, Denys and Di Penta, Massimiliano and Bavota, Gabriele},
  year      = {2021},
  pages     = {1–1}
}

@misc{peng2023,
  title         = {The Impact of AI on Developer Productivity: Evidence from GitHub Copilot},
  author        = {Sida Peng and Eirini Kalliamvakou and Peter Cihon and Mert Demirer},
  year          = {2023},
  eprint        = {2302.06590},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2302.06590}
}

@article{weber2024,
  author     = {Weber, Thomas and Brandmaier, Maximilian and Schmidt, Albrecht and Mayer, Sven},
  title      = {Significant Productivity Gains through Programming with Large Language Models},
  year       = {2024},
  issue_date = {June 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {8},
  number     = {EICS},
  url        = {https://doi.org/10.1145/3661145},
  doi        = {10.1145/3661145},
  abstract   = {Large language models like GPT and Codex drastically alter many daily tasks, including programming, where they can rapidly generate code from natural language or informal specifications. Thus, they will change what it means to be a programmer and how programmers act during software development. This work explores how AI assistance for code generation impacts productivity. In our user study (N=24), we asked programmers to complete Python programming tasks supported by a) an auto-complete interface using GitHub Copilot, b) a conversational system using GPT-3, and c) traditionally with just the web browser. Aside from significantly increasing productivity metrics, participants displayed distinctive usage patterns and strategies, highlighting that the form of presentation and interaction affects how users engage with these systems. Our findings emphasize the benefits of AI-assisted coding and highlight the different design challenges for these systems.},
  journal    = {Proc. ACM Hum.-Comput. Interact.},
  articleno  = {256},
  numpages   = {29},
  keywords   = {github copilot, gpt, language models, programming, software development, user study}
}

@misc{bakal2025,
  title         = {Experience with GitHub Copilot for Developer Productivity at Zoominfo},
  author        = {Gal Bakal and Ali Dasdan and Yaniv Katz and Michael Kaufman and Guy Levin},
  year          = {2025},
  eprint        = {2501.13282},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2501.13282}
}

@misc{takerngsaksiri2023,
  title         = {Students' Perspective on AI Code Completion: Benefits and Challenges},
  author        = {Wannita Takerngsaksiri and Cleshan Warusavitarne and Christian Yaacoub and Matthew Hee Keng Hou and Chakkrit Tantithamthavorn},
  year          = {2023},
  eprint        = {2311.00177},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2311.00177}
}

@misc{giagnorio2025,
  title         = {Why Personalizing Deep Learning-Based Code Completion Tools Matters},
  author        = {Alessandro Giagnorio and Alberto Martin-Lopez and Gabriele Bavota},
  year          = {2025},
  eprint        = {2503.14201},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2503.14201}
}

@misc{svyatkovskiy2020,
  title         = {IntelliCode Compose: Code Generation Using Transformer},
  author        = {Alexey Svyatkovskiy and Shao Kun Deng and Shengyu Fu and Neel Sundaresan},
  year          = {2020},
  eprint        = {2005.08025},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2005.08025}
}

@article{estoup1916,
  added-at  = {2007-05-03T17:19:57.000+0200},
  address   = {Paris},
  author    = {Estoup, J. B.},
  biburl    = {https://www.bibsonomy.org/bibtex/272fb4f23ac99287d6a46a2be5fd0f01f/andreab},
  interhash = {492f9278bea34585716c1c1326c224ca},
  intrahash = {72fb4f23ac99287d6a46a2be5fd0f01f},
  journal   = {Institut Stenographique de France},
  keywords  = {d4.1 distribution estoup first frequency mandelbrot tagora word zipf},
  publisher = {Gauthier-Villars},
  timestamp = {2007-05-03T17:19:57.000+0200},
  title     = {Les Gammes Stenographiques},
  year      = 1916
}

@article{gage1994,
  title   = {A new algorithm for data compression},
  author  = {Philip Gage},
  journal = {The C Users Journal archive},
  year    = {1994},
  volume  = {12},
  pages   = {23-38},
  url     = {https://api.semanticscholar.org/CorpusID:59804030}
}

@misc{sennrich2015,
  title         = {Neural Machine Translation of Rare Words with Subword Units},
  author        = {Rico Sennrich and Barry Haddow and Alexandra Birch},
  year          = {2015},
  eprint        = {1508.07909},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1508.07909}
}

@inproceedings{harris1954,
  title  = {Distributional Structure},
  author = {Zellig S. Harris},
  year   = {1954},
  url    = {https://api.semanticscholar.org/CorpusID:86680084}
}

@misc{vaswani2017,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2017},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1706.03762}
}

@misc{bahdanau2014,
  title         = {Neural Machine Translation by Jointly Learning to Align and Translate},
  author        = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  year          = {2014},
  eprint        = {1409.0473},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1409.0473}
}

@misc{baevski2018,
  title         = {Adaptive Input Representations for Neural Language Modeling},
  author        = {Alexei Baevski and Michael Auli},
  year          = {2018},
  eprint        = {1809.10853},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1809.10853}
}

@misc{child2019,
  title         = {Generating Long Sequences with Sparse Transformers},
  author        = {Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
  year          = {2019},
  eprint        = {1904.10509},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1904.10509}
}

@misc{wang2019,
  title         = {Learning Deep Transformer Models for Machine Translation},
  author        = {Qiang Wang and Bei Li and Tong Xiao and Jingbo Zhu and Changliang Li and Derek F. Wong and Lidia S. Chao},
  year          = {2019},
  eprint        = {1906.01787},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1906.01787}
}

@misc{xiong2020,
  title         = {On Layer Normalization in the Transformer Architecture},
  author        = {Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tie-Yan Liu},
  year          = {2020},
  eprint        = {2002.04745},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2002.04745}
}

@misc{ba2016,
  title         = {Layer Normalization},
  author        = {Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  year          = {2016},
  eprint        = {1607.06450},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1607.06450}
}

@misc{zhang2019,
  title         = {Root Mean Square Layer Normalization},
  author        = {Biao Zhang and Rico Sennrich},
  year          = {2019},
  eprint        = {1910.07467},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1910.07467}
}

@misc{hendrycks2016,
  title         = {Gaussian Error Linear Units (GELUs)},
  author        = {Dan Hendrycks and Kevin Gimpel},
  year          = {2016},
  eprint        = {1606.08415},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1606.08415}
}

@misc{shazeer2020,
  title         = {GLU Variants Improve Transformer},
  author        = {Noam Shazeer},
  year          = {2020},
  eprint        = {2002.05202},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2002.05202}
}

@article{srivastava2014,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@misc{su2021,
  title         = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  author        = {Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
  year          = {2021},
  eprint        = {2104.09864},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2104.09864}
}

@misc{barbero2024,
  title         = {Round and Round We Go! What makes Rotary Positional Encodings useful?},
  author        = {Federico Barbero and Alex Vitvitskyi and Christos Perivolaropoulos and Razvan Pascanu and Petar Veličković},
  year          = {2024},
  eprint        = {2410.06205},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2410.06205}
}

@misc{loshchilov2017,
  title         = {Decoupled Weight Decay Regularization},
  author        = {Ilya Loshchilov and Frank Hutter},
  year          = {2017},
  eprint        = {1711.05101},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1711.05101}
}

@misc{kingma2014,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = {2014},
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1412.6980}
}

@misc{holtzman2019,
  title         = {The Curious Case of Neural Text Degeneration},
  author        = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
  year          = {2019},
  eprint        = {1904.09751},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1904.09751}
}

@misc{rozière2023,
  title         = {Code Llama: Open Foundation Models for Code},
  author        = {Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
  year          = {2023},
  eprint        = {2308.12950},
  archiveprefix = {arXiv},
  howpublished  = {online},
  urldate       = {2025-05-16},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.12950}
}

@misc{hui2024,
  title         = {Qwen2.5-Coder Technical Report},
  author        = {Binyuan Hui and Jian Yang and Zeyu Cui and Jiaxi Yang and Dayiheng Liu and Lei Zhang and Tianyu Liu and Jiajun Zhang and Bowen Yu and Keming Lu and Kai Dang and Yang Fan and Yichang Zhang and An Yang and Rui Men and Fei Huang and Bo Zheng and Yibo Miao and Shanghaoran Quan and Yunlong Feng and Xingzhang Ren and Xuancheng Ren and Jingren Zhou and Junyang Lin},
  year          = {2024},
  eprint        = {2409.12186},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2409.12186}
}

@misc{guo2024,
  title         = {DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence},
  author        = {Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
  year          = {2024},
  eprint        = {2401.14196},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2401.14196}
}

@misc{huang2024,
  title         = {OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models},
  author        = {Siming Huang and Tianhao Cheng and J. K. Liu and Jiaran Hao and Liuyihan Song and Yang Xu and J. Yang and Jiaheng Liu and Chenchen Zhang and Linzheng Chai and Ruifeng Yuan and Zhaoxiang Zhang and Jie Fu and Qian Liu and Ge Zhang and Zili Wang and Yuan Qi and Yinghui Xu and Wei Chu},
  year          = {2024},
  eprint        = {2411.04905},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2411.04905}
}

@misc{bavarian2022,
  title         = {Efficient Training of Language Models to Fill in the Middle},
  author        = {Mohammad Bavarian and Heewoo Jun and Nikolas Tezak and John Schulman and Christine McLeavey and Jerry Tworek and Mark Chen},
  year          = {2022},
  eprint        = {2207.14255},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2207.14255}
}

@misc{donahue2020,
  title         = {Enabling Language Models to Fill in the Blanks},
  author        = {Chris Donahue and Mina Lee and Percy Liang},
  year          = {2020},
  eprint        = {2005.05339},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2005.05339}
}

@misc{aghajanyan2022,
  title         = {CM3: A Causal Masked Multimodal Model of the Internet},
  author        = {Armen Aghajanyan and Bernie Huang and Candace Ross and Vladimir Karpukhin and Hu Xu and Naman Goyal and Dmytro Okhonko and Mandar Joshi and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer},
  year          = {2022},
  eprint        = {2201.07520},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2201.07520}
}

@misc{fried2022,
  title         = {InCoder: A Generative Model for Code Infilling and Synthesis},
  author        = {Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Wen-tau Yih and Luke Zettlemoyer and Mike Lewis},
  year          = {2022},
  eprint        = {2204.05999},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2204.05999}
}

@misc{allal2023,
  title         = {SantaCoder: don't reach for the stars!},
  author        = {Loubna Ben Allal and Raymond Li and Denis Kocetkov and Chenghao Mou and Christopher Akiki and Carlos Munoz Ferrandis and Niklas Muennighoff and Mayank Mishra and Alex Gu and Manan Dey and Logesh Kumar Umapathi and Carolyn Jane Anderson and Yangtian Zi and Joel Lamy Poirier and Hailey Schoelkopf and Sergey Troshin and Dmitry Abulkhanov and Manuel Romero and Michael Lappert and Francesco De Toni and Bernardo García del Río and Qian Liu and Shamik Bose and Urvashi Bhattacharyya and Terry Yue Zhuo and Ian Yu and Paulo Villegas and Marco Zocca and Sourab Mangrulkar and David Lansky and Huu Nguyen and Danish Contractor and Luis Villa and Jia Li and Dzmitry Bahdanau and Yacine Jernite and Sean Hughes and Daniel Fried and Arjun Guha and Harm de Vries and Leandro von Werra},
  year          = {2023},
  eprint        = {2301.03988},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2301.03988}
}

@misc{dibia2022,
  title         = {Aligning Offline Metrics and Human Judgments of Value for Code Generation Models},
  author        = {Victor Dibia and Adam Fourney and Gagan Bansal and Forough Poursabzi-Sangdeh and Han Liu and Saleema Amershi},
  year          = {2022},
  eprint        = {2210.16494},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2210.16494}
}

@book{murphy2022,
  author    = {Kevin P. Murphy},
  title     = {Probabilistic Machine Learning: An introduction},
  publisher = {MIT Press},
  year      = 2022,
  url       = {http://probml.github.io/book1}
}

@misc{chen2021,
  title         = {Evaluating Large Language Models Trained on Code},
  author        = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year          = {2021},
  eprint        = {2107.03374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2107.03374}
}

@misc{ren2020,
  title         = {CodeBLEU: a Method for Automatic Evaluation of Code Synthesis},
  author        = {Shuo Ren and Daya Guo and Shuai Lu and Long Zhou and Shujie Liu and Duyu Tang and Neel Sundaresan and Ming Zhou and Ambrosio Blanco and Shuai Ma},
  year          = {2020},
  eprint        = {2009.10297},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2009.10297}
}

@inproceedings{papineni2002,
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  title     = {BLEU: a method for automatic evaluation of machine translation},
  year      = {2002},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  url       = {https://doi.org/10.3115/1073083.1073135},
  doi       = {10.3115/1073083.1073135},
  abstract  = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
  booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
  pages     = {311–318},
  numpages  = {8},
  location  = {Philadelphia, Pennsylvania},
  series    = {ACL '02}
}

@inproceedings{lin2004,
  title     = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
  author    = {Lin, Chin-Yew},
  booktitle = {Text Summarization Branches Out},
  year      = {2004},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W04-1013/},
  pages     = {74--81}
}

@inproceedings{popovic2015,
  title     = {chr{F}: character n-gram {F}-score for automatic {MT} evaluation},
  author    = {Popovi{\'c}, Maja},
  editor    = {Bojar, Ond{\v{r}}ej  and
               Chatterjee, Rajan  and
               Federmann, Christian  and
               Haddow, Barry  and
               Hokamp, Chris  and
               Huck, Matthias  and
               Logacheva, Varvara  and
               Pecina, Pavel},
  booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W15-3049/},
  doi       = {10.18653/v1/W15-3049},
  pages     = {392--395}
}

@inproceedings{banarjee2005,
  title     = {{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments},
  author    = {Banerjee, Satanjeev  and Lavie, Alon},
  booktitle = {Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization},
  year      = {2005},
  address   = {Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/W05-0909},
  pages     = {65--72}
}

@misc{zhang2019,
  title         = {BERTScore: Evaluating Text Generation with BERT},
  author        = {Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  year          = {2019},
  eprint        = {1904.09675},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1904.09675}
}

@inproceedings{tran2019,
  title     = {Does BLEU Score Work for Code Migration?},
  url       = {http://dx.doi.org/10.1109/ICPC.2019.00034},
  doi       = {10.1109/icpc.2019.00034},
  booktitle = {2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC)},
  publisher = {IEEE},
  author    = {Tran, Ngoc and Tran, Hieu and Nguyen, Son and Nguyen, Hoan and Nguyen, Tien},
  year      = {2019},
  pages     = {165–176}
}

@article{evtikhiev2022,
  title     = {Out of the BLEU: How should we assess quality of the Code Generation models?},
  volume    = {203},
  issn      = {0164-1212},
  url       = {http://dx.doi.org/10.1016/j.jss.2023.111741},
  doi       = {10.1016/j.jss.2023.111741},
  journal   = {Journal of Systems and Software},
  publisher = {Elsevier BV},
  author    = {Evtikhiev, Mikhail and Bogomolov, Egor and Sokolov, Yaroslav and Bryksin, Timofey},
  year      = {2022},
  pages     = {111741}
}

@misc{liu2023,
  title         = {RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems},
  author        = {Tianyang Liu and Canwen Xu and Julian McAuley},
  year          = {2023},
  eprint        = {2306.03091},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2306.03091}
}

@misc{bogomolov2024,
  title         = {Long Code Arena: a Set of Benchmarks for Long-Context Code Models},
  author        = {Egor Bogomolov and Aleksandra Eliseeva and Timur Galimzyanov and Evgeniy Glukhov and Anton Shapkin and Maria Tigina and Yaroslav Golubev and Alexander Kovrigin and Arie van Deursen and Maliheh Izadi and Timofey Bryksin},
  year          = {2024},
  eprint        = {2406.11612},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2406.11612}
}

@misc{pan2024,
  title         = {Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?},
  author        = {Zhenyu Pan and Rongyu Cao and Yongchang Cao and Yingwei Ma and Binhua Li and Fei Huang and Han Liu and Yongbin Li},
  year          = {2024},
  eprint        = {2410.01353},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2410.01353}
}

@misc{ding2023,
  title         = {CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion},
  author        = {Yangruibo Ding and Zijian Wang and Wasi Uddin Ahmad and Hantian Ding and Ming Tan and Nihal Jain and Murali Krishna Ramanathan and Ramesh Nallapati and Parminder Bhatia and Dan Roth and Bing Xiang},
  year          = {2023},
  eprint        = {2310.11248},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2310.11248}
}

@misc{wu2024a,
  title         = {Repoformer: Selective Retrieval for Repository-Level Code Completion},
  author        = {Di Wu and Wasi Uddin Ahmad and Dejiao Zhang and Murali Krishna Ramanathan and Xiaofei Ma},
  year          = {2024a},
  eprint        = {2403.10059},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2403.10059}
}

@misc{zhang2023a,
  title         = {RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation},
  author        = {Fengji Zhang and Bei Chen and Yue Zhang and Jacky Keung and Jin Liu and Daoguang Zan and Yi Mao and Jian-Guang Lou and Weizhu Chen},
  year          = {2023},
  eprint        = {2303.12570},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2303.12570}
}

@misc{wu2024b,
  title         = {RepoMasterEval: Evaluating Code Completion via Real-World Repositories},
  author        = {Qinyun Wu and Chao Peng and Pengfei Gao and Ruida Hu and Haoyu Gan and Bo Jiang and Jinhe Tang and Zhiwen Deng and Zhanming Guan and Cuiyun Gao and Xia Liu and Ping Yang},
  year          = {2024b},
  eprint        = {2408.03519},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2408.03519}
}

@misc{deng2024,
  title         = {R\textsuperscript{2}C\textsuperscript{2}-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models},
  author        = {Ken Deng and Jiaheng Liu and He Zhu and Congnan Liu and Jingxin Li and Jiakai Wang and Peng Zhao and Chenchen Zhang and Yanan Wu and Xueqiao Yin and Yuanxing Zhang and Wenbo Su and Bangyu Xiang and Tiezheng Ge and Bo Zheng},
  year          = {2024},
  eprint        = {2406.01359},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2406.01359}
}

@misc{liu2024,
  title         = {\textsc{M\textsuperscript{2}rc-Eval}: Massively Multilingual Repository-level Code Completion Evaluation},
  author        = {Jiaheng Liu and Ken Deng and Congnan Liu and Jian Yang and Shukai Liu and He Zhu and Peng Zhao and Linzheng Chai and Yanan Wu and Ke Jin and Ge Zhang and Zekun Wang and Guoan Zhang and Bangyu Xiang and Wenbo Su and Bo Zheng},
  year          = {2024},
  eprint        = {2410.21157},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2410.21157}
}

@misc{ding2022,
  title         = {CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context},
  author        = {Yangruibo Ding and Zijian Wang and Wasi Uddin Ahmad and Murali Krishna Ramanathan and Ramesh Nallapati and Parminder Bhatia and Dan Roth and Bing Xiang},
  year          = {2022},
  eprint        = {2212.10007},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2212.10007}
}

@article{raychev2016,
  author     = {Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
  title      = {Probabilistic model for code with decision trees},
  year       = {2016},
  issue_date = {October 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {51},
  number     = {10},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/3022671.2984041},
  doi        = {10.1145/3022671.2984041},
  abstract   = {In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc). The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy. Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82\% and 69\%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy.},
  journal    = {SIGPLAN Not.},
  pages      = {731–747},
  numpages   = {17},
  keywords   = {Code Completion, Decision Trees, Probabilistic Models of Code}
}

@inproceedings{allamanis2013,
  author    = {Allamanis, Miltiadis and Sutton, Charles},
  booktitle = {2013 10th Working Conference on Mining Software Repositories (MSR)},
  title     = {Mining source code repositories at massive scale using language modeling},
  year      = {2013},
  volume    = {},
  number    = {},
  pages     = {207-216},
  keywords  = {Training;Entropy;Java;Measurement;Predictive models;Complexity theory;Software},
  doi       = {10.1109/MSR.2013.6624029}
}

@article{robertson2009,
  author     = {Robertson, Stephen and Zaragoza, Hugo},
  title      = {The Probabilistic Relevance Framework: BM25 and Beyond},
  year       = {2009},
  issue_date = {April 2009},
  publisher  = {Now Publishers Inc.},
  address    = {Hanover, MA, USA},
  volume     = {3},
  number     = {4},
  issn       = {1554-0669},
  url        = {https://doi.org/10.1561/1500000019},
  doi        = {10.1561/1500000019},
  abstract   = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
  journal    = {Found. Trends Inf. Retr.},
  pages      = {333–389},
  numpages   = {57}
}

@inproceedings{sapronov2025,
  title     = {On Pretraining For Project-Level Code Completion},
  author    = {Maksim Sapronov and Evgeniy Glukhov},
  booktitle = {ICLR 2025 Third Workshop on Deep Learning for Code},
  year      = {2025},
  url       = {https://openreview.net/forum?id=t9RN9WX4Ic}
}

@misc{xiong2023,
  title         = {Effective Long-Context Scaling of Foundation Models},
  author        = {Wenhan Xiong and Jingyu Liu and Igor Molybog and Hejia Zhang and Prajjwal Bhargava and Rui Hou and Louis Martin and Rashi Rungta and Karthik Abinav Sankararaman and Barlas Oguz and Madian Khabsa and Han Fang and Yashar Mehdad and Sharan Narang and Kshitiz Malik and Angela Fan and Shruti Bhosale and Sergey Edunov and Mike Lewis and Sinong Wang and Hao Ma},
  year          = {2023},
  eprint        = {2309.16039},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2309.16039}
}

@misc{hui2024,
  title         = {Qwen2.5-Coder Technical Report},
  author        = {Binyuan Hui and Jian Yang and Zeyu Cui and Jiaxi Yang and Dayiheng Liu and Lei Zhang and Tianyu Liu and Jiajun Zhang and Bowen Yu and Keming Lu and Kai Dang and Yang Fan and Yichang Zhang and An Yang and Rui Men and Fei Huang and Bo Zheng and Yibo Miao and Shanghaoran Quan and Yunlong Feng and Xingzhang Ren and Xuancheng Ren and Jingren Zhou and Junyang Lin},
  year          = {2024},
  eprint        = {2409.12186},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2409.12186}
}

@misc{kaplan2020,
  title         = {Scaling Laws for Neural Language Models},
  author        = {Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  year          = {2020},
  eprint        = {2001.08361},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2001.08361}
}

@misc{brown2020,
  title         = {Language Models are Few-Shot Learners},
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year          = {2020},
  eprint        = {2005.14165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2005.14165}
}

@misc{hahn2023,
  title         = {A Theory of Emergent In-Context Learning as Implicit Structure Induction},
  author        = {Michael Hahn and Navin Goyal},
  year          = {2023},
  eprint        = {2303.07971},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2303.07971}
}

@misc{tay2022,
  title         = {Efficient Transformers: A Survey},
  author        = {Yi Tay and Mostafa Dehghani and Dara Bahri and Donald Metzler},
  year          = {2022},
  eprint        = {2009.06732},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2009.06732}
}

@misc{liu2021,
  title         = {What Makes Good In-Context Examples for GPT-$3$?},
  author        = {Jiachang Liu and Dinghan Shen and Yizhe Zhang and Bill Dolan and Lawrence Carin and Weizhu Chen},
  year          = {2021},
  eprint        = {2101.06804},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2101.06804}
}

@misc{lewis2020,
  title         = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author        = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year          = {2021},
  eprint        = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2005.11401}
}

@misc{chen2023,
  title         = {Extending Context Window of Large Language Models via Positional Interpolation},
  author        = {Shouyuan Chen and Sherman Wong and Liangjian Chen and Yuandong Tian},
  year          = {2023},
  eprint        = {2306.15595},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2306.15595}
}

@misc{peng2023,
  title         = {YaRN: Efficient Context Window Extension of Large Language Models},
  author        = {Bowen Peng and Jeffrey Quesnelle and Honglu Fan and Enrico Shippole},
  year          = {2023},
  eprint        = {2309.00071},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2309.00071}
}

@online{nvidia2024,
  author       = {{NVIDIA Corporation}},
  title        = {Mixed Precision Training},
  year         = {2023},
  howpublished = {online},
  urldate      = {2025-05-13},
  url          = {https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html}
}

@misc{pascanu2013,
  title         = {On the difficulty of training Recurrent Neural Networks},
  author        = {Razvan Pascanu and Tomas Mikolov and Yoshua Bengio},
  year          = {2013},
  eprint        = {1211.5063},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1211.5063}
}

@misc{ding2021,
  title         = {CogView: Mastering Text-to-Image Generation via Transformers},
  author        = {Ming Ding and Zhuoyi Yang and Wenyi Hong and Wendi Zheng and Chang Zhou and Da Yin and Junyang Lin and Xu Zou and Zhou Shao and Hongxia Yang and Jie Tang},
  year          = {2021},
  eprint        = {2105.13290},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2105.13290}
}

@misc{zhang2023b,
  title         = {Dive into Deep Learning},
  author        = {Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
  year          = {2023},
  eprint        = {2106.11342},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/2106.11342}
}

@misc{zehui2019,
  title         = {DropAttention: A Regularization Method for Fully-Connected Self-Attention Networks},
  author        = {Lin Zehui and Pengfei Liu and Luyao Huang and Junkun Chen and Xipeng Qiu and Xuanjing Huang},
  year          = {2019},
  eprint        = {1907.11065},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1907.11065}
}

@misc{labach2019,
  title         = {Survey of Dropout Methods for Deep Neural Networks},
  author        = {Alex Labach and Hojjat Salehinejad and Shahrokh Valaee},
  year          = {2019},
  eprint        = {1904.13310},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE},
  howpublished  = {online},
  urldate       = {2025-05-16},
  url           = {https://arxiv.org/abs/1904.13310}
}