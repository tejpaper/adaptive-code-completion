\chapter*{Conclusion}\addcontentsline{toc}{chapter}{Conclusion}\markboth{Conclusion}{Conclusion}

In conclusion, the objectives of this thesis have been accomplished. The theory of modern repository-level code completion systems is covered in \nameref{part:conceptual-framework}, providing an overview of the code completion task, a general formulation of language modeling, and deep learning methods addressing this area. Subsequently, the specifics of project-level completion are discussed through the lens of language modeling. The relevance and importance of the in-context learning phenomenon are described. To further explore the nuances of repository-level code completion, the general problems of long context are presented along with methods to address them. The research aspect of this work is detailed in \nameref{part:applied-research}, which includes answers to four research questions and a description of the practical framework developed to support these investigations.

The conducted research has yielded several significant findings regarding repository-level code completion. The results substantiate the crucial role of repository context in enhancing completion quality. Contemporary base Code LLMs possess sufficient training, with their in-context learning capabilities showing only marginal improvement through downstream fine-tuning on different context composition strategies. Data leakage in the repository context during the context extension phase adversely affects the model's in-context abilities, while other composers maintain baseline performance integrity. The context composition strategy employed during the repository-level pre-training stage demonstrates minimal impact on final model quality, suggesting that RoPE adjustment serves as the primary driver of long-context improvements and underscores its usage limitations. Additionally, computational requirements of the repository-level pre-training stage can be substantially reduced while maintaining competitive results. For instance, file-level training, even without repository context, remains highly effective. Finally, gradient masking produces a statistically significant yet marginal performance decrease on composers generating inlier context.

Overall, this thesis contributes to the evolution of code completion models by underscoring theoretical foundations in the conceptual framework and offering valuable empirical insights for practitioners through comprehensive research on context composition techniques for repository-level understanding.
